{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import pytorch_lightning as L\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import v2 as  transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Swinv2Config, Swinv2Model, AutoImageProcessor, AutoModelForImageClassification\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from pytorch_lightning_sam_callback import SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, path_col, mode='train'):\n",
    "        self.df = df\n",
    "        self.path_col = path_col\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # OpenCV를 사용하여 이미지를 NumPy 배열로 로드\n",
    "        image = cv2.imread(row[self.path_col])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR에서 RGB로 변환\n",
    "        image = image / 256.0  # 정규화\n",
    "\n",
    "        if self.mode in ['train', 'val']:\n",
    "            label = row['class']\n",
    "            data = {\n",
    "                'image': image,\n",
    "                'label': label\n",
    "            }\n",
    "            return data\n",
    "        elif self.mode == 'inference':\n",
    "            data = {\n",
    "                'image': image\n",
    "            }\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCollateFn:\n",
    "    def __init__(self, transform, mode):\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # 변환된 이미지만을 리스트에 저장\n",
    "        images = [self.transform(image=data['image'])['image'] for data in batch]\n",
    "        pixel_values = torch.stack(images)\n",
    "\n",
    "        if self.mode in ['train', 'val']:\n",
    "            labels = torch.LongTensor([data['label'] for data in batch])\n",
    "            return {\n",
    "                'pixel_values': pixel_values,\n",
    "                'label': labels,\n",
    "            }\n",
    "        elif self.mode == 'inference':\n",
    "            return {\n",
    "                'pixel_values': pixel_values,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Tanh(),\n",
    "            nn.LazyLinear(25),\n",
    "        )\n",
    "\n",
    "#     @torch.compile\n",
    "    def forward(self, x, label=None):\n",
    "        x = self.model(x).pooler_output\n",
    "        x = self.clf(x)\n",
    "        loss = None\n",
    "        if label is not None:\n",
    "            loss = nn.CrossEntropyLoss()(x, label)\n",
    "        probs = nn.LogSoftmax(dim=-1)(x)\n",
    "        return probs, loss\n",
    "\n",
    "class LitCustomModel(L.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = CustomModel(model)\n",
    "        self.validation_step_output = []\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=1e-5)\n",
    "        return opt\n",
    "\n",
    "    def training_step(self, batch, batch_idx=None):\n",
    "        x = batch['pixel_values']\n",
    "        label = batch['label']\n",
    "        probs, loss = self.model(x, label)\n",
    "        self.log(f\"train_loss\", loss, on_step=True, on_epoch=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx=None):\n",
    "        x = batch['pixel_values']\n",
    "        label = batch['label']\n",
    "        probs, loss = self.model(x, label)\n",
    "        self.validation_step_output.append([probs,label])\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx=None):\n",
    "        x = batch['pixel_values']\n",
    "        probs, _ = self.model(x)\n",
    "        return probs\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        pred = torch.cat([x for x, _ in self.validation_step_output]).cpu().detach().numpy().argmax(1)\n",
    "        label = torch.cat([label for _, label in self.validation_step_output]).cpu().detach().numpy()\n",
    "        score = f1_score(label, pred, average='macro')\n",
    "        self.log(\"val_score\", score)\n",
    "        self.validation_step_output.clear()\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "N_SPLIT = 5\n",
    "BATCH_SIZE = 12\n",
    "L.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./datas/train.csv')\n",
    "train_df['img_path'] = train_df['img_path'].apply(lambda x: os.path.join('./datas', x))\n",
    "train_df['upscale_img_path'] = train_df['upscale_img_path'].apply(lambda x: os.path.join('./datas', x))\n",
    "le = LabelEncoder()\n",
    "train_df['class'] = le.fit_transform(train_df['label'])\n",
    "if not len(train_df) == len(os.listdir('./datas/train')):\n",
    "    raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=N_SPLIT, random_state=SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = albu.Compose([\n",
    "                             albu.Resize(256, 256, interpolation=cv2.INTER_CUBIC), \n",
    "                             albu.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n",
    "                             albu.OneOf([\n",
    "                                         albu.HorizontalFlip(p=1),\n",
    "                                         albu.RandomRotate90(p=1),\n",
    "                                         albu.VerticalFlip(p=1),\n",
    "                                         ], p=1),\n",
    "                             ToTensorV2()\n",
    "                            ])\n",
    "val_transform = albu.Compose([\n",
    "                             albu.Resize(256, 256, interpolation=cv2.INTER_CUBIC),\n",
    "                             albu.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n",
    "                             ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "train_collate_fn = CustomCollateFn(train_transform, 'train')\n",
    "val_collate_fn = CustomCollateFn(val_transform, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\내 드라이브\\DACON\\DACON-Bird_Image_Classification\\bird\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "g:\\내 드라이브\\DACON\\DACON-Bird_Image_Classification\\bird\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:653: Checkpoint directory G:\\내 드라이브\\DACON\\DACON-Bird_Image_Classification\\checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | CustomModel | 195 M \n",
      "--------------------------------------\n",
      "195 M     Trainable params\n",
      "0         Non-trainable params\n",
      "195 M     Total params\n",
      "780.812   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea23183507d46c79adc9332d00b825e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\내 드라이브\\DACON\\DACON-Bird_Image_Classification\\bird\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "g:\\내 드라이브\\DACON\\DACON-Bird_Image_Classification\\bird\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d0ecefc1634ea1884a2dc03b883a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\내 드라이브\\DACON\\DACON-Bird_Image_Classification\\bird\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "g:\\내 드라이브\\DACON\\DACON-Bird_Image_Classification\\bird\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "g:\\내 드라이브\\DACON\\DACON-Bird_Image_Classification\\bird\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:653: Checkpoint directory G:\\내 드라이브\\DACON\\DACON-Bird_Image_Classification\\checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type        | Params\n",
      "--------------------------------------\n",
      "0 | model | CustomModel | 195 M \n",
      "--------------------------------------\n",
      "195 M     Trainable params\n",
      "0         Non-trainable params\n",
      "195 M     Total params\n",
      "780.812   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b9388309b947df83a2638f2badcdaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\내 드라이브\\DACON\\DACON-Bird_Image_Classification\\bird\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "g:\\내 드라이브\\DACON\\DACON-Bird_Image_Classification\\bird\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c854fc70a5641bea5b7549c8a2056f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold_idx, (train_index, val_index) in enumerate(skf.split(train_df, train_df['class'])):\n",
    "    train_fold_df = train_df.loc[train_index,:]\n",
    "    val_fold_df = train_df.loc[val_index,:]\n",
    "\n",
    "    train_dataset = CustomDataset(train_fold_df, 'img_path', mode='train')\n",
    "    val_dataset = CustomDataset(val_fold_df, 'img_path', mode='val')\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, collate_fn=train_collate_fn, batch_size=BATCH_SIZE)\n",
    "    val_dataloader = DataLoader(val_dataset, collate_fn=val_collate_fn, batch_size=BATCH_SIZE*2)\n",
    "\n",
    "    model = Swinv2Model.from_pretrained(\"microsoft/swinv2-large-patch4-window12to16-192to256-22kto1k-ft\")\n",
    "    lit_model = LitCustomModel(model)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_score',\n",
    "        mode='max',\n",
    "        dirpath='./checkpoints/',\n",
    "        filename=f'swinv2-SAM-fold_idx={fold_idx}'+'-{epoch:02d}-{train_loss:.4f}-{val_score:.4f}',\n",
    "        save_top_k=1,\n",
    "        save_weights_only=True,\n",
    "        verbose=True\n",
    "    )\n",
    "    earlystopping_callback = EarlyStopping(monitor=\"val_score\", mode=\"max\", patience=3)\n",
    "    trainer = L.Trainer(max_epochs=100, accelerator='auto', precision=32, callbacks=[checkpoint_callback, earlystopping_callback, SAM()], val_check_interval=0.5)\n",
    "    trainer.fit(lit_model, train_dataloader, val_dataloader)\n",
    "\n",
    "    model.cpu()\n",
    "    lit_model.cpu()\n",
    "    del model, lit_model, checkpoint_callback, earlystopping_callback, trainer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./datas/test.csv')\n",
    "test_df['img_path'] = test_df['img_path'].apply(lambda x: os.path.join('./datas', x))\n",
    "if not len(test_df) == len(os.listdir('./datas/test')):\n",
    "    raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = albu.Compose([\n",
    "                             albu.Resize(256, 256, interpolation=cv2.INTER_CUBIC),\n",
    "                             albu.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n",
    "                             ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "test_collate_fn = CustomCollateFn(test_transform, 'inference')\n",
    "test_dataset = CustomDataset(test_df, 'img_path', mode='inference')\n",
    "test_dataloader = DataLoader(test_dataset, collate_fn=test_collate_fn, batch_size=BATCH_SIZE*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_preds = []\n",
    "for checkpoint_path in glob('./checkpoints/swinv2-large-resize*.ckpt'):\n",
    "    model = Swinv2Model.from_pretrained(\"microsoft/swinv2-large-patch4-window12to16-192to256-22kto1k-ft\")\n",
    "    lit_model = LitCustomModel.load_from_checkpoint(checkpoint_path, model=model)\n",
    "    trainer = L.Trainer( accelerator='auto', precision=32)\n",
    "    preds = trainer.predict(lit_model, test_dataloader)\n",
    "    preds = torch.cat(preds,dim=0).detach().cpu().numpy().argmax(1)\n",
    "    fold_preds.append(preds)\n",
    "pred_ensemble = list(map(lambda x: np.bincount(x).argmax(),np.stack(fold_preds,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./datas/sample_submission.csv')\n",
    "submission['label'] = le.inverse_transform(pred_ensemble)\n",
    "submission.to_csv('./submissions/swinv2_large_resize.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bird",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
